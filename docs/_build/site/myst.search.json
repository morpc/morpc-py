{"version":"1","records":[{"hierarchy":{"lvl1":"morpc-py"},"type":"lvl1","url":"/","position":0},{"hierarchy":{"lvl1":"morpc-py"},"content":"","type":"content","url":"/","position":1},{"hierarchy":{"lvl1":"morpc-py","lvl2":"Introducion"},"type":"lvl2","url":"/#introducion","position":2},{"hierarchy":{"lvl1":"morpc-py","lvl2":"Introducion"},"content":"The MORPC data team maintains a package with contains commonly-used constants, mappings, and functions to allow for code-reuse in multiple scripts.  The package documentation and code is available at the \n\nmorpc-py repository in GitHub.\n\nThis package is still in development but will contain the following modules:\n\nmorpc - Main library.  Includes contents which are broadly applicable for MORPC’s work, including MORPC branding, region definitions and utilities, and general purpose data manipulation functions.\n\nmorpc.frictionless -  Functions and classes for working with metadata, including schemas, resources, and data packages. These are for internal processes that us the \n\nfrictionless-py package. Frictionless was implemented roughly 2025 to manage all metadata and to develop workflow documentation.\n\nmorpc.census - Constants and functions that are relevant when working with Census data, including decennial census, ACS, and PEP.\n\nmorpc.rest_apt - Tools for working with ArcGIS Online REST API, including scripts for creating local copies as frictionless resources.\n\nmorpc.plot - Tools for standard plots which leverage MORPC branding and data visualization best practices.\n\nmorpc.color - Various tools for working with colors, largely implemented through morpc.plot.","type":"content","url":"/#introducion","position":3},{"hierarchy":{"lvl1":"morpc-py","lvl2":"Installation"},"type":"lvl2","url":"/#installation","position":4},{"hierarchy":{"lvl1":"morpc-py","lvl2":"Installation"},"content":"A version of the package is available via pip and can be installed by a standard pip install.$ pip install morpc","type":"content","url":"/#installation","position":5},{"hierarchy":{"lvl1":"morpc-py","lvl3":"Dev Install","lvl2":"Installation"},"type":"lvl3","url":"/#dev-install","position":6},{"hierarchy":{"lvl1":"morpc-py","lvl3":"Dev Install","lvl2":"Installation"},"content":"As the package is still in development, the best way to install it is via the pip \n\n-editable option. To do so:\n\nPull the most recent verision of the jordan_dev (branch name may change later) to a local repo.\n\nUsing the following command to install an editable version, replacing the path to the correct location.$ pip install -e \"C:/path/to/folder/morpc-py/\"\n\nImport the package as normal$ import morpc\n\nTo contribute to the development branch make changes in the local repo and push them to git. When making changes to the package, you will have to re-import the package. If you are working in a Jupyter environment you will have to do this after restarting the kernel.","type":"content","url":"/#dev-install","position":7},{"hierarchy":{"lvl1":"morpc-py","lvl2":"Documentation"},"type":"lvl2","url":"/#documentation","position":8},{"hierarchy":{"lvl1":"morpc-py","lvl2":"Documentation"},"content":"See \n\ndocs for documentation.\n\n(in development) there will be a livemark site for documenatation.","type":"content","url":"/#documentation","position":9},{"hierarchy":{"lvl1":"morpc.color Demo"},"type":"lvl1","url":"/morpc-color-demo","position":0},{"hierarchy":{"lvl1":"morpc.color Demo"},"content":"","type":"content","url":"/morpc-color-demo","position":1},{"hierarchy":{"lvl1":"morpc.color Demo","lvl2":"Import morpc package"},"type":"lvl2","url":"/morpc-color-demo#import-morpc-package","position":2},{"hierarchy":{"lvl1":"morpc.color Demo","lvl2":"Import morpc package"},"content":"\n\nimport morpc\n\n","type":"content","url":"/morpc-color-demo#import-morpc-package","position":3},{"hierarchy":{"lvl1":"morpc.color Demo","lvl2":"Get standard HEX color codes"},"type":"lvl2","url":"/morpc-color-demo#get-standard-hex-color-codes","position":4},{"hierarchy":{"lvl1":"morpc.color Demo","lvl2":"Get standard HEX color codes"},"content":"\n\nThe get_colors() class provides access to a json file that contains various useful definitions of colors. It takes one argument colorDictPath='../morpc/color/morpc_colors.json' which is the relative path to the json file.\n\nThe json file is stored in the attribute morpc_colors.\n\nmorpc.color.get_colors().morpc_colors\n\n","type":"content","url":"/morpc-color-demo#get-standard-hex-color-codes","position":5},{"hierarchy":{"lvl1":"morpc.color Demo","lvl2":"Key Colors"},"type":"lvl2","url":"/morpc-color-demo#key-colors","position":6},{"hierarchy":{"lvl1":"morpc.color Demo","lvl2":"Key Colors"},"content":"\n\nThe standard colors are retrieved using .KEYS instance.\n\nmorpc.color.get_colors().KEYS\n\n","type":"content","url":"/morpc-color-demo#key-colors","position":7},{"hierarchy":{"lvl1":"morpc.color Demo","lvl2":"Plot color strips from hex lists to see colors"},"type":"lvl2","url":"/morpc-color-demo#plot-color-strips-from-hex-lists-to-see-colors","position":8},{"hierarchy":{"lvl1":"morpc.color Demo","lvl2":"Plot color strips from hex lists to see colors"},"content":"\n\nYou can plot a list of hex codes using the plot_from_hex_list() function. In the following example, we pass the values of the key colors to see them. The plot includes the HLS values, a grey values, and the hex code.\n\nmorpc.color.plot_from_hex_list(morpc.color.get_colors().KEYS.values())\n\n","type":"content","url":"/morpc-color-demo#plot-color-strips-from-hex-lists-to-see-colors","position":9},{"hierarchy":{"lvl1":"morpc.color Demo","lvl2":"Sequential color gradients for each color"},"type":"lvl2","url":"/morpc-color-demo#sequential-color-gradients-for-each-color","position":10},{"hierarchy":{"lvl1":"morpc.color Demo","lvl2":"Sequential color gradients for each color"},"content":"\n\nEach color has an associated gradient. These gradients can be returned using the .SEQ() function. Simply pass the color name to the funcion.\n\nmorpc.color.plot_from_hex_list(morpc.color.get_colors().SEQ('midblue').hex_list)\n\nfor color in morpc.color.get_colors().KEYS.keys():\n    morpc.color.plot_from_hex_list(morpc.color.get_colors().SEQ(color).hex_list)\n\nLimit the number of colors returned in the gradient by passing an integer 1 through 12 to the n =  attribute.\n\nmorpc.color.plot_from_hex_list(morpc.color.get_colors().SEQ('gold', 4).hex_list)\n\n","type":"content","url":"/morpc-color-demo#sequential-color-gradients-for-each-color","position":11},{"hierarchy":{"lvl1":"morpc.color Demo","lvl2":"Two color sequential gradients"},"type":"lvl2","url":"/morpc-color-demo#two-color-sequential-gradients","position":12},{"hierarchy":{"lvl1":"morpc.color Demo","lvl2":"Two color sequential gradients"},"content":"\n\nPass a list of two color names to .SEQ2() method to get a split gradient.\n\nmorpc.color.plot_from_hex_list(morpc.color.get_colors().SEQ2(['gold', 'darkblue']).hex_list)\n\nmorpc.color.plot_from_hex_list(morpc.color.get_colors().SEQ2(['rose', 'blue']).hex_list)\n\n","type":"content","url":"/morpc-color-demo#two-color-sequential-gradients","position":13},{"hierarchy":{"lvl1":"morpc.color Demo","lvl2":"Three color sequential gradients"},"type":"lvl2","url":"/morpc-color-demo#three-color-sequential-gradients","position":14},{"hierarchy":{"lvl1":"morpc.color Demo","lvl2":"Three color sequential gradients"},"content":"\n\nThe same can be done with three colors using .SEQ3() method.\n\nmorpc.color.plot_from_hex_list(morpc.get_colors().SEQ3(['gold', 'darkgreen', 'darkblue']).hex_list)\n\n","type":"content","url":"/morpc-color-demo#three-color-sequential-gradients","position":15},{"hierarchy":{"lvl1":"morpc.color Demo","lvl2":"Color maps"},"type":"lvl2","url":"/morpc-color-demo#color-maps","position":16},{"hierarchy":{"lvl1":"morpc.color Demo","lvl2":"Color maps"},"content":"\n\nUsing any method, you can return a color map in the form of the gradient using the .cmap instance.\n\nmorpc.color.get_colors().SEQ3(['gold', 'darkgreen', 'darkblue']).cmap\n\n","type":"content","url":"/morpc-color-demo#color-maps","position":17},{"hierarchy":{"lvl1":"morpc.color Demo","lvl2":"Diverging color gradients"},"type":"lvl2","url":"/morpc-color-demo#diverging-color-gradients","position":18},{"hierarchy":{"lvl1":"morpc.color Demo","lvl2":"Diverging color gradients"},"content":"\n\nUse the .DIV() method can be used to create diverging gradients and color maps.\n\nmorpc.color.plot_from_hex_list(morpc.get_colors().DIV(['gold','darkblue']).hex_list)\n\nmorpc.color.plot_from_hex_list(morpc.color.get_colors().DIV(['rose','darkgreen']).hex_list)\n\n","type":"content","url":"/morpc-color-demo#diverging-color-gradients","position":19},{"hierarchy":{"lvl1":"morpc.color Demo","lvl2":"Qualitative color groups"},"type":"lvl2","url":"/morpc-color-demo#qualitative-color-groups","position":20},{"hierarchy":{"lvl1":"morpc.color Demo","lvl2":"Qualitative color groups"},"content":"\n\nUse the .QUAL() method to return groups for qualitative data. It selects a number of grouped lightness variations of each color.\n\nmorpc.color.plot_from_hex_list(morpc.color.get_colors().QUAL(20).hex_list)\n\n","type":"content","url":"/morpc-color-demo#qualitative-color-groups","position":21},{"hierarchy":{"lvl1":"morpc.color Demo","lvl2":"Testing color maps for color blindness accessibility"},"type":"lvl2","url":"/morpc-color-demo#testing-color-maps-for-color-blindness-accessibility","position":22},{"hierarchy":{"lvl1":"morpc.color Demo","lvl2":"Testing color maps for color blindness accessibility"},"content":"\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nnp.random.seed(19680801)\ndata = np.random.randn(30, 30)\nfig, ax = plt.subplots()\npsm = ax.pcolormesh(data, cmap=morpc.color.get_colors().DIV(['gold', 'bluegreen']).cmap, rasterized=True, vmin=-4, vmax=4)\nfig.colorbar(psm, ax=ax)\n\nfrom daltonize import daltonize\ndaltonize.simulate_mpl(fig, color_deficit='p')","type":"content","url":"/morpc-color-demo#testing-color-maps-for-color-blindness-accessibility","position":23},{"hierarchy":{"lvl1":"morpc.color Demo"},"type":"lvl1","url":"/morpc-color-demo-1","position":0},{"hierarchy":{"lvl1":"morpc.color Demo"},"content":"","type":"content","url":"/morpc-color-demo-1","position":1},{"hierarchy":{"lvl1":"morpc.color Demo","lvl2":"Import morpc package"},"type":"lvl2","url":"/morpc-color-demo-1#import-morpc-package","position":2},{"hierarchy":{"lvl1":"morpc.color Demo","lvl2":"Import morpc package"},"content":"\n\nimport morpc\n\n","type":"content","url":"/morpc-color-demo-1#import-morpc-package","position":3},{"hierarchy":{"lvl1":"morpc.color Demo","lvl2":"Get standard HEX color codes"},"type":"lvl2","url":"/morpc-color-demo-1#get-standard-hex-color-codes","position":4},{"hierarchy":{"lvl1":"morpc.color Demo","lvl2":"Get standard HEX color codes"},"content":"\n\nThe get_colors() class provides access to a json file that contains various useful definitions of colors. It takes one argument colorDictPath='../morpc/color/morpc_colors.json' which is the relative path to the json file.\n\nThe json file is stored in the attribute morpc_colors.\n\nmorpc.color.get_colors().morpc_colors\n\n","type":"content","url":"/morpc-color-demo-1#get-standard-hex-color-codes","position":5},{"hierarchy":{"lvl1":"morpc.color Demo","lvl2":"Key Colors"},"type":"lvl2","url":"/morpc-color-demo-1#key-colors","position":6},{"hierarchy":{"lvl1":"morpc.color Demo","lvl2":"Key Colors"},"content":"\n\nThe standard colors are retrieved using .KEYS instance.\n\nmorpc.color.get_colors().KEYS\n\n","type":"content","url":"/morpc-color-demo-1#key-colors","position":7},{"hierarchy":{"lvl1":"morpc.color Demo","lvl2":"Plot color strips from hex lists to see colors"},"type":"lvl2","url":"/morpc-color-demo-1#plot-color-strips-from-hex-lists-to-see-colors","position":8},{"hierarchy":{"lvl1":"morpc.color Demo","lvl2":"Plot color strips from hex lists to see colors"},"content":"\n\nYou can plot a list of hex codes using the plot_from_hex_list() function. In the following example, we pass the values of the key colors to see them. The plot includes the HLS values, a grey values, and the hex code.\n\nmorpc.color.plot_from_hex_list(morpc.color.get_colors().KEYS.values())\n\n","type":"content","url":"/morpc-color-demo-1#plot-color-strips-from-hex-lists-to-see-colors","position":9},{"hierarchy":{"lvl1":"morpc.color Demo","lvl2":"Sequential color gradients for each color"},"type":"lvl2","url":"/morpc-color-demo-1#sequential-color-gradients-for-each-color","position":10},{"hierarchy":{"lvl1":"morpc.color Demo","lvl2":"Sequential color gradients for each color"},"content":"\n\nEach color has an associated gradient. These gradients can be returned using the .SEQ() function. Simply pass the color name to the funcion.\n\nmorpc.color.plot_from_hex_list(morpc.color.get_colors().SEQ('midblue').hex_list)\n\n\n\nfor color in morpc.color.get_colors().KEYS.keys():\n    morpc.color.plot_from_hex_list(morpc.color.get_colors().SEQ(color).hex_list)\n\nLimit the number of colors returned in the gradient by passing an integer 1 through 12 to the n =  attribute.\n\nmorpc.color.plot_from_hex_list(morpc.color.get_colors().SEQ('gold', 4).hex_list)\n\n","type":"content","url":"/morpc-color-demo-1#sequential-color-gradients-for-each-color","position":11},{"hierarchy":{"lvl1":"morpc.color Demo","lvl2":"Two color sequential gradients"},"type":"lvl2","url":"/morpc-color-demo-1#two-color-sequential-gradients","position":12},{"hierarchy":{"lvl1":"morpc.color Demo","lvl2":"Two color sequential gradients"},"content":"\n\nPass a list of two color names to .SEQ2() method to get a split gradient.\n\nmorpc.color.plot_from_hex_list(morpc.color.get_colors().SEQ2(['gold', 'darkblue']).hex_list)\n\n\n\nmorpc.color.plot_from_hex_list(morpc.color.get_colors().SEQ2(['rose', 'blue']).hex_list)\n\n","type":"content","url":"/morpc-color-demo-1#two-color-sequential-gradients","position":13},{"hierarchy":{"lvl1":"morpc.color Demo","lvl2":"Three color sequential gradients"},"type":"lvl2","url":"/morpc-color-demo-1#three-color-sequential-gradients","position":14},{"hierarchy":{"lvl1":"morpc.color Demo","lvl2":"Three color sequential gradients"},"content":"\n\nThe same can be done with three colors using .SEQ3() method.\n\nmorpc.color.plot_from_hex_list(morpc.get_colors().SEQ3(['gold', 'darkgreen', 'darkblue']).hex_list)\n\n","type":"content","url":"/morpc-color-demo-1#three-color-sequential-gradients","position":15},{"hierarchy":{"lvl1":"morpc.color Demo","lvl2":"Color maps"},"type":"lvl2","url":"/morpc-color-demo-1#color-maps","position":16},{"hierarchy":{"lvl1":"morpc.color Demo","lvl2":"Color maps"},"content":"\n\nUsing any method, you can return a color map in the form of the gradient using the .cmap instance.\n\nmorpc.color.get_colors().SEQ3(['gold', 'darkgreen', 'darkblue']).cmap\n\n","type":"content","url":"/morpc-color-demo-1#color-maps","position":17},{"hierarchy":{"lvl1":"morpc.color Demo","lvl2":"Diverging color gradients"},"type":"lvl2","url":"/morpc-color-demo-1#diverging-color-gradients","position":18},{"hierarchy":{"lvl1":"morpc.color Demo","lvl2":"Diverging color gradients"},"content":"\n\nUse the .DIV() method can be used to create diverging gradients and color maps.\n\nmorpc.color.plot_from_hex_list(morpc.get_colors().DIV(['gold','darkblue']).hex_list)\n\n\n\nmorpc.color.plot_from_hex_list(morpc.color.get_colors().DIV(['rose','darkgreen']).hex_list)\n\n","type":"content","url":"/morpc-color-demo-1#diverging-color-gradients","position":19},{"hierarchy":{"lvl1":"morpc.color Demo","lvl2":"Qualitative color groups"},"type":"lvl2","url":"/morpc-color-demo-1#qualitative-color-groups","position":20},{"hierarchy":{"lvl1":"morpc.color Demo","lvl2":"Qualitative color groups"},"content":"\n\nUse the .QUAL() method to return groups for qualitative data. It selects a number of grouped lightness variations of each color.\n\nmorpc.color.plot_from_hex_list(morpc.color.get_colors().QUAL(20).hex_list)\n\n","type":"content","url":"/morpc-color-demo-1#qualitative-color-groups","position":21},{"hierarchy":{"lvl1":"morpc.color Demo","lvl2":"Testing color maps for color blindness accessibility"},"type":"lvl2","url":"/morpc-color-demo-1#testing-color-maps-for-color-blindness-accessibility","position":22},{"hierarchy":{"lvl1":"morpc.color Demo","lvl2":"Testing color maps for color blindness accessibility"},"content":"\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nnp.random.seed(19680801)\ndata = np.random.randn(30, 30)\nfig, ax = plt.subplots()\npsm = ax.pcolormesh(data, cmap=morpc.color.get_colors().DIV(['gold', 'bluegreen']).cmap, rasterized=True, vmin=-4, vmax=4)\nfig.colorbar(psm, ax=ax)\n\n\n\nfrom daltonize import daltonize\ndaltonize.simulate_mpl(fig, color_deficit='p')\n\n\n\n","type":"content","url":"/morpc-color-demo-1#testing-color-maps-for-color-blindness-accessibility","position":23},{"hierarchy":{"lvl1":"Demo for morpc.plot"},"type":"lvl1","url":"/morpc-plot-demo","position":0},{"hierarchy":{"lvl1":"Demo for morpc.plot"},"content":"","type":"content","url":"/morpc-plot-demo","position":1},{"hierarchy":{"lvl1":"Demo for morpc.plot","lvl2":"Plot from Resource"},"type":"lvl2","url":"/morpc-plot-demo#plot-from-resource","position":2},{"hierarchy":{"lvl1":"Demo for morpc.plot","lvl2":"Plot from Resource"},"content":"Plot a graph or chart from a frictionless resource based on schema and data types.\n\nimport morpc\n\n","type":"content","url":"/morpc-plot-demo#plot-from-resource","position":3},{"hierarchy":{"lvl1":"Demo for morpc.plot","lvl2":"Build a sample resource file."},"type":"lvl2","url":"/morpc-plot-demo#build-a-sample-resource-file","position":4},{"hierarchy":{"lvl1":"Demo for morpc.plot","lvl2":"Build a sample resource file."},"content":"\n\ndf, resource, schema = morpc.frictionless.load_data('../../morpc-pop-collect/output_data/morpc-pop-collect.resource.yaml')\n\ndf = df.sort_values('VINTAGE_PERIOD', ascending=False).groupby(['GEOIDFQ', 'REFERENCE_PERIOD']).head(1).sort_values('REFERENCE_PERIOD')\n\ngrouped = df.groupby('GEOIDFQ')\n\nname, df = [x for x in grouped][0]\n\ndf\n\nimport pandas as pd\nconf_u = df[df['VALUE_TYPE']=='FORECAST'][['REFERENCE_PERIOD', 'CONF_LIMIT_UPPER']].rename(columns = {'CONF_LIMIT_UPPER':'POP'})\nconf_l = df[df['VALUE_TYPE']=='FORECAST'][['REFERENCE_PERIOD', 'CONF_LIMIT_LOWER']].rename(columns = {'CONF_LIMIT_LOWER':'POP'})\nconf_u = conf_u.sort_values('REFERENCE_PERIOD', ascending=False)\nconf = pd.concat([conf_u, conf_l])\n\nimport plotnine\nplot = (plotnine.ggplot()\n + plotnine.geom_path(df, plotnine.aes(x='REFERENCE_PERIOD', y='POP', color='VALUE_TYPE'))\n + plotnine.theme_bw()\n + plotnine.scale_color_manual(morpc.color.get_colors().QUAL(2).hex_list)\n + plotnine.scale_x_date(breaks='5 years', date_labels='%Y')\n + plotnine.theme(\n     axis_text_x=(plotnine.element_text(rotation=65))\n )\n + plotnine.scale_y_continuous(breaks=ybreaks, limits=(ybreaks[0], ybreaks[-1]))\n )","type":"content","url":"/morpc-plot-demo#build-a-sample-resource-file","position":5},{"hierarchy":{"lvl1":""},"type":"lvl1","url":"/morpc-py-countylookup","position":0},{"hierarchy":{"lvl1":""},"content":"","type":"content","url":"/morpc-py-countylookup","position":1},{"hierarchy":{"lvl1":"Demos of features of the morpc python package"},"type":"lvl1","url":"/morpc-py-demos","position":0},{"hierarchy":{"lvl1":"Demos of features of the morpc python package"},"content":"","type":"content","url":"/morpc-py-demos","position":1},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl2":"Introduction"},"type":"lvl2","url":"/morpc-py-demos#introduction","position":2},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl2":"Introduction"},"content":"\n\nThe MORPC data team maintains a package with contains commonly-used constants, mappings, and functions to allow for code-reuse in multiple scripts.  The package documentation and code is available at the \n\nmorpc-py repository in GitHub.\n\nThis package is still in development but will contain the following modules:\n\nmorpc - Main library.  Includes contents which are broadly applicable for MORPC’s work, including MORPC branding, region definitions and utilities, and general purpose data manipulation functions.\n\nmorpc.frictionless -  Functions and classes for working with metadata, including schemas, resources, and data packages. These are for internal processes that us the \n\nfrictionless-py package. Frictionless was implemented roughly 2025 to manage all metadata and to develop workflow documentation.\n\nmorpc.census - Constants and functions that are relevant when working with Census data, including decennial census, ACS, and PEP.\n\n","type":"content","url":"/morpc-py-demos#introduction","position":3},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl2":"Installation"},"type":"lvl2","url":"/morpc-py-demos#installation","position":4},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl2":"Installation"},"content":"\n\nInstall via pip.\n\n# !pip install morpc --upgrade\n\n","type":"content","url":"/morpc-py-demos#installation","position":5},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl3":"Import morpc package","lvl2":"Installation"},"type":"lvl3","url":"/morpc-py-demos#import-morpc-package","position":6},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl3":"Import morpc package","lvl2":"Installation"},"content":"\n\nimport morpc\n\n","type":"content","url":"/morpc-py-demos#import-morpc-package","position":7},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl2":"Conversion factors"},"type":"lvl2","url":"/morpc-py-demos#conversion-factors","position":8},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl2":"Conversion factors"},"content":"\n\nAs of Jan 2024, the following commonly used conversion factors are available in the library. Review the \n\nmorpc/morpc.py to see if others are available.\n\n","type":"content","url":"/morpc-py-demos#conversion-factors","position":9},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl3":"Area","lvl2":"Conversion factors"},"type":"lvl3","url":"/morpc-py-demos#area","position":10},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl3":"Area","lvl2":"Conversion factors"},"content":"\n\nSquare feet per acre\n\nmorpc.CONST_SQFT_PER_ACRE\n\n","type":"content","url":"/morpc-py-demos#area","position":11},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl3":"Region definitions","lvl2":"Conversion factors"},"type":"lvl3","url":"/morpc-py-demos#region-definitions","position":12},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl3":"Region definitions","lvl2":"Conversion factors"},"content":"\n\nThe following lists represent various definitions for “Central Ohio” based on collections of counties.\n\nfor name in morpc.CONST_REGIONS.keys():\n    print(\"Region name: {}\".format(name))\n    print(\"Counties in region: {}\\n\".format(morpc.CONST_REGIONS[name]))\n\n","type":"content","url":"/morpc-py-demos#region-definitions","position":13},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl3":"County three-letter abbreviations","lvl2":"Conversion factors"},"type":"lvl3","url":"/morpc-py-demos#county-three-letter-abbreviations","position":14},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl3":"County three-letter abbreviations","lvl2":"Conversion factors"},"content":"\n\nMap each MORPC county name to its three-letter abbreviation.\n\nmorpc.CONST_COUNTY_ABBREV\n\nMap each three-letter abbreviation back to its county name.\n\nmorpc.CONST_COUNTY_EXPAND\n\nNote that ‘MRW’ is the three-letter abbreviation for Morrow county that is used by ODOT. Sometimes it may be desired to use ‘MOR’ instead.  In that case, you can use the following code to update both mappings.\n\nmorpc.CONST_COUNTY_ABBREV[\"Morrow\"] = 'MOR'\nmorpc.CONST_COUNTY_EXPAND = {value: key for key, value in morpc.CONST_COUNTY_ABBREV.items()}\n\nNow you can see the new mappings:\n\nprint(morpc.CONST_COUNTY_ABBREV[\"Morrow\"])\nprint(morpc.CONST_COUNTY_EXPAND[\"MOR\"])\n\nTo revert to the old mapping you can either use a code block similar to the one above, or simply reload the library:\n\nimport importlib\nimportlib.reload(morpc)\n\nNow the original mappings are restored.\n\nprint(morpc.CONST_COUNTY_ABBREV[\"Morrow\"])\nprint(morpc.CONST_COUNTY_EXPAND[\"MRW\"])\n\n","type":"content","url":"/morpc-py-demos#county-three-letter-abbreviations","position":15},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl2":"County identifiers (GEOID)"},"type":"lvl2","url":"/morpc-py-demos#county-identifiers-geoid","position":16},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl2":"County identifiers (GEOID)"},"content":"\n\nMap each MORPC county name to its five-character Census GEOID.  Note that the IDs are strings.  They are not integers and should not be handled as such.\n\nmorpc.CONST_COUNTY_NAME_TO_ID\n\nMap each GEOID back to its county name.\n\nmorpc.CONST_COUNTY_ID_TO_NAME\n\n","type":"content","url":"/morpc-py-demos#county-identifiers-geoid","position":17},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl2":"Summary level identifiers."},"type":"lvl2","url":"/morpc-py-demos#summary-level-identifiers","position":18},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl2":"Summary level identifiers."},"content":"\n\nSummary level lookups for geographic jurisdictions. The summary levels include the Census sumlevel numbers, as well as some morpc summary levels, beginning with “M”\n\nmorpc.SUMLEVEL_LOOKUP\n\nmorpc.HIERARCHY_STRING_LOOKUP\n\n","type":"content","url":"/morpc-py-demos#summary-level-identifiers","position":19},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl2":"countyLookup() Class"},"type":"lvl2","url":"/morpc-py-demos#countylookup-class","position":20},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl2":"countyLookup() Class"},"content":"\n\n","type":"content","url":"/morpc-py-demos#countylookup-class","position":21},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl3":"List counties and convert between county names and codes (Central Ohio, Ohio, or U.S.)","lvl2":"countyLookup() Class"},"type":"lvl3","url":"/morpc-py-demos#list-counties-and-convert-between-county-names-and-codes-central-ohio-ohio-or-u-s","position":22},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl3":"List counties and convert between county names and codes (Central Ohio, Ohio, or U.S.)","lvl2":"countyLookup() Class"},"content":"\n\nThe library includes a Python class called countyLookup. Upon instantiation, this object is pre-loaded with a dataframe describing a set of counties whose scope is specified by the user.  The object includes methods for listing the counties by their names or GEOIDs and for two-way conversion between name and GEOID.\n\nscope=\"morpc\"     Default. Loads only the counties in the MORPC 15-county region (see CONST_REGIONS['15-County Region'] above)\n\nscope=\"corpo\"     Loads only the counties in the CORPO region (see CONST_REGIONS['CORPO Region'] above)\n\nscope=\"ohio\"      Loads all counties in Ohio\n\nscope=\"us\"      Loads all counties in the United States\n\nNOTE: As of Jan 2024, some methods are not supported for scope=“us”.  See details below.\n\nYou can create an object containing the MORPC 15 counties as follows:\n\ncountyLookup = morpc.countyLookup()\n\nOr if you prefer to be explicit:\n\ncountyLookup = morpc.countyLookup(scope=\"morpc\")\n\nEither way, the object is populated with the following dataframe.\n\ncountyLookup.df\n\nYou can create a list of the names of the counties:\n\ncountyLookup.list_names()\n\nOr list their IDs:\n\ncountyLookup.list_ids()\n\nYou can also look up the ID for a county given its name.\n\ncountyLookup.get_id(\"Hocking\")\n\nOr look up its name given its ID.\n\ncountyLookup.get_name(\"39091\")\n\n","type":"content","url":"/morpc-py-demos#list-counties-and-convert-between-county-names-and-codes-central-ohio-ohio-or-u-s","position":23},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl2":"varLookup() class"},"type":"lvl2","url":"/morpc-py-demos#varlookup-class","position":24},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl2":"varLookup() class"},"content":"\n\nStandard variable lookup class\n\nReads the list of “standard” variables from a lookup table.  Provides dataframe access to the list of variables, as well as an alias cross-reference table.\n\n## PLACEHOLDER FOR EXAMPLES\n\n","type":"content","url":"/morpc-py-demos#varlookup-class","position":25},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl2":"Write data and charts to Excel"},"type":"lvl2","url":"/morpc-py-demos#write-data-and-charts-to-excel","position":26},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl2":"Write data and charts to Excel"},"content":"\n\nExcel-based charts are exceptionally useful to our customers because they are easy for our customers to manipulate, style, and include in downstream products such as PowerPoint slides.  They are, however, inconvenient to product programmatically.  The following functions are intended to simplify the production of Excel-based charts that are consistent with MORPC branding and, eventually, with Data & Mapping visualization standards.\n\n","type":"content","url":"/morpc-py-demos#write-data-and-charts-to-excel","position":27},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl4":"data_chart_to_excel( )","lvl2":"Write data and charts to Excel"},"type":"lvl4","url":"/morpc-py-demos#data-chart-to-excel","position":28},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl4":"data_chart_to_excel( )","lvl2":"Write data and charts to Excel"},"content":"\n\nThis function will create an Excel worksheet consisting of the contents of a pandas dataframe (as a formatted table) and, optionally, a chart to visualize the series included in the dataframe.  The simplest invocation will produce a table and a basic column (vertical bar) chart with default formatting that is consistent with MORPC branding guidelines, however the user can specify many of options supported by the xlsxwriter library (\n\nhttps://​xlsxwriter​.readthedocs​.io/).\n\nThe following blocks demonstrates some simple use cases.  First, create a dataframe with demonstration data.\n\nimport pandas as pd\nimport os\nimport morpc\n\nd = {'col1': [1, 2, 3, 4], 'col2':[3, 4, 5, 6]}\ndf = pd.DataFrame(data=d)\ndf\n\nNext create an Excel object using the xlsxwriter package.  The object is linked to an Excel workbook, as indicated by the path in the first argument.\n\n# Create a directory to store the output (for demonstration purposes only)\nif not os.path.exists(\"./temp_data\"):\n    os.makedirs(\"./temp_data\")\n\nwriter = pd.ExcelWriter(\"./temp_data/dataChartToExcelOutput.xlsx\", engine='xlsxwriter')\n\nThe following block will create a new worksheet in the Excel object which contains a table representing the dataframe and column chart displaying the series in the table.  The new worksheet will be called “Sheet1” since no sheet name was specified.  Default presentation settings will be used since we did not specify any settings.  This will result in a column (vertical bar) chart.\n\nNote: You will not be able to view the spreadsheet itself until the writer object is closed in a later block.\n\nmorpc.data_chart_to_excel(df, writer)  \n\nThe following block will add another worksheet to the xlsxwriter object.  This time we specified a sheet name (“LineChart”) and a chart type (“line”), so the code will create the same table as the previous command but will produce a line chart instead of a column chart.  As before, the default presentation settings will be used.\n\nmorpc.data_chart_to_excel(df, writer, sheet_name=\"LineChart\", chartType=\"line\")\n\nThe following block goes a step further and specifies a subtype for the chart.  Specifically it creates a stacked column chart.  As before, the default presentation settings will be used.  For more information about what chart types and subtypes are available, see \n\nhttps://​xlsxwriter​.readthedocs​.io​/workbook​.html​#workbook​-add​-chart.  The supported chart types as of this writing include column, bar, and line.  The stacked subtype has been minimally tested for column and bar charts.  Other chart types and subtypes may or may not work without further improvements to the function.\n\nmorpc.data_chart_to_excel(df, writer, sheet_name=\"Stacked\", chartType=\"column\", chartOptions={\"subtype\":\"stacked\"})\n\nThe next block demonstrates the “bar” (horiztontal bar) chart type and applies some custom presentation settings, specifically a set of user-specified colors and titles, and omission of the legend, which is displayed by default.\n\nmorpc.data_chart_to_excel(df, writer, sheet_name=\"Custom\", chartType=\"bar\", chartOptions={\n    \"colors\": [\"cyan\",\"magenta\"],                   # Specify a custom color\n    \"hideLegend\": True,                             # Hide the legend\n    \"titles\": {                                     # Specify the chart title and axis titles\n        \"chartTitle\": \"My Chart\",\n        \"xTitle\": \"My independent variable\",\n        \"yTitle\": \"My dependent variable\",\n    }\n})\n\nFinally, we have to close the xlsxwriter object to finalize the Excel workbook and make it readable.\n\nwriter.close()\n\nNow you should be able to open the Excel document at ./temp_data/dataChartToExcelOutput.xlsx\n\nNote that many more customizations are possible.  To learn more, uncomment and run the following block, or enter the command in your own notebook or a Python interpreter.\n\n# help(morpc.data_chart_to_excel)\n\n","type":"content","url":"/morpc-py-demos#data-chart-to-excel","position":29},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl2":"Load spatial data"},"type":"lvl2","url":"/morpc-py-demos#load-spatial-data","position":30},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl2":"Load spatial data"},"content":"\n\nOften we want to make a copy of some input data and work with the copy, for example to protect the original data or to create an archival copy of it so that we can replicate the process later.  With tabular data this is simple, but with spatial data it can be tricky.  Shapefiles actually consist of up to six files, so it is necessary to copy them all.  Geodatabases may contain many layers in addition to the one we care about.  The load_spatial_data() function simplifies the process of reading the data and (optionally) making an archival copy. It has three parameters:\n\nsourcePath - The path to the geospatial data. It may be a file path or URL. In the case of a Shapefile, this should point to the .shp file or a zipped file that contains all of the Shapefile components. You can point to other zipped contents as well, but see caveats below.\n\nlayerName (required for GPKG and GDB, optional for SHP) - The name of the layer that you wish to extract from a GeoPackage or File Geodatabase.  Not required for Shapefiles, but may be specified for use in the archival copy (see below)\n\ndriverName (required for zipped data or data with non-standard file extension) - which \n\nGDAL driver to use to read the file. Script will attempt to infer this from the file extension, but you must specify it if the data is zipped, if the file extension is non-standard, or if the extension cannot be determined from the path (e.g. if the path is an API query)\n\narchiveDir (optional) - The path to the directory where a copy of a data should be archived.  If this is specified, the data will be archived in this location as a GeoPackage.  The function will determine the file name and layer name from the specified parameters, using generic values if necessary.\n\narchiveFileName (optional) - If archiveDir is specified, you may use this to specify the name of the archival GeoPackage.  Omit the extension.  If this is unspecified, the function will assign the file name automatically using a generic value if necessary.\n\nThe following example loads data from the MORPC Mid-Ohio Open Data website, however you can also load data from a local path or network drive.\n\nimport geopandas as gpd\n\n# Create a directory to store the archival data (for demonstration purposes only)\nif not os.path.exists(\"./temp_data\"):\n    os.makedirs(\"./temp_data\")\n\n# Load the data and create an archival copy\ngdf = morpc.load_spatial_data(\n    sourcePath=\"https://opendata.arcgis.com/api/v3/datasets/e42b50fbd17a47739c2a7695778c498e_17/downloads/data?format=shp&spatialRefId=3735&where=1%3D1\", \n    layerName=\"MORPC MPO Boundary\",\n    driverName=\"ESRI Shapefile\",\n    archiveDir=\"./temp_data\"\n)\n\nLet’s take a look at the data and make sure it loaded correctly.\n\ngdf.drop(columns=\"Updated\").explore() ## avoid datetime column JSON error\n\nNow let’s read the archival copy and make sure it looks the same.  We’ll use the load_spatial_data() function again, but this time we won’t make an archival copy.\n\ngdfArchive = morpc.load_spatial_data(\"./temp_data/MORPC MPO Boundary.gpkg\", layerName=\"MORPC MPO Boundary\")\n\ngdfArchive.drop(columns=\"Updated\").explore()\n\n","type":"content","url":"/morpc-py-demos#load-spatial-data","position":31},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl2":"Assign geographic identifiers"},"type":"lvl2","url":"/morpc-py-demos#assign-geographic-identifiers","position":32},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl2":"Assign geographic identifiers"},"content":"\n\nSometimes we have a set of locations and we would like to know what geography (county, zipcode, etc.) they fall in. The assign_geo_identifiers() function takes a set of georeference points and a list of geography levels and determines for each level which area each point falls in.  The function takes two parameters:\n\npoints - a GeoPandas GeoDataFrame consisting of the points of interest\n\ngeographies - A Python list of one or more strings in which each element corresponds to a geography level. You can specify as many levels as you want from the following list, however note that the function must download the polygons and perform the analysis for each level so if you specify many levels it may take a long time.\n\n“county” - County (Census TIGER)\n\n“tract” - Not currently implemented\n\n“blockgroup” - Not currently implemented\n\n“block” - Not currently implemented\n\n“zcta” - Not currently implemented\n\n“place” - Census place (Census TIGER)\n\n“placecombo” - Not currently implemented\n\n“juris” - Not currently implemented\n\n“region15County” - Not currently implemented\n\n“region10County” - Not currently implemented\n\n“regionCORPO” - Not currently implemented\n\n“regionMPO” - Not currently implemented\n\nNOTE: Many of the geography levels are not currently implemented.  They are being implemented as they are needed.  If you need one that has not yet been implemented, please contact Adam Porr (or implement it yourself).\n\nIn the following example, we will assign labels for the “county” and “place” geography levels to libraries in MORPC’s Points of Interest layer.  First we’ll download just the library locations from Mid-Ohio Open Data using the ArcGIS REST API.\n\nurl = \"https://services1.arcgis.com/EjjnBtwS9ivTGI8x/arcgis/rest/services/Points_of_Interest/FeatureServer/0/query?outFields=*&where=%22type%22=%27Library%27&f=geojson\"\nlibrariesRaw = gpd.read_file(url)\n\nThe data incudes a bunch of fields that we don’t need.  For clarity, extract only the relevant fields.\n\nlibraries = librariesRaw.copy().filter(items=['NAME', 'ADDRESS','geometry'], axis=\"columns\")\n\nlibraries.head()\n\nLet’s take a look at the library locations.\n\nlibraries.explore(style_kwds={\"radius\":4})\n\nUse the assign_geo_identifiers() function to iterate through the requested geography levels (in this case “county” and “place”), labeling each point with the identifier of the geography in each level where the point is located.\n\nlibrariesEnriched = morpc.assign_geo_identifiers(libraries, [\"county\",\"place\"])\n\nNote that two columns have been added to the dataframe, one that contains the identifier for the county the library is located in and one that contains the identifier for the place.\n\nlibrariesEnriched.head()\n\nLet’s take a look at libraries, symbolizing each according to the county where it is located.\n\nlibrariesEnriched.explore(column=\"id_county\", style_kwds={\"radius\":4})\n\nLet’s take another look, this time symbolizing each library according to the place where it is located.  The legend has been suppressed because there are too many unique values, but you can hover over each point to see the place identifier that has been assigned to it.\n\nlibrariesEnriched.explore(column=\"id_place\", style_kwds={\"radius\":4}, legend=False)\n\n","type":"content","url":"/morpc-py-demos#assign-geographic-identifiers","position":33},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl2":"morpc.frictionless - Schema tools (TableSchema)"},"type":"lvl2","url":"/morpc-py-demos#morpc-frictionless-schema-tools-tableschema","position":34},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl2":"morpc.frictionless - Schema tools (TableSchema)"},"content":"\n\nAs of January 2024 the Data Team is considering a new standard for machine-readable metadata, namely \n\nTableSchema.  TableSchema is a schema for tabular formats that includes many of the features for Avro (see above) plus rich types and constraints. TableSchema is supported in \n\nPython and \n\nR, and the libraries include many utilty functions.\n\nThe foundation of the morpc.frictionless is \n\nfrictionless-py. The functions are written to create and load resources.\n\nThe foundation of the frictionless framework are \n\nresouces. Resources are structured json or yaml files that include metadata for the a file or number of files.\n\ndf = pd.read_excel('./temp_data/dataChartToExcelOutput.xlsx') ## import sample data from temp_data\n\ndf.columns = [\"column1\", \"column2\", \"column3\"] ## give some reasonable names to columns\n\ndf.to_csv('./temp_data/temp_df.csv', index=False) ## save a csv\n\nTypically we will create some constant variable name for the file, resource, and schema. The resource and schema are stored in yaml files.\n\nRESOURCE_DIR = './temp_data/'\nTABLE_FILE_NAME = 'temp_df.csv'\nTABLE_RESOURCE_NAME = TABLE_FILE_NAME.replace('.csv', '.resource.yaml')\nTABLE_SCHEMA_NAME = TABLE_FILE_NAME.replace('.csv', '.schema.yaml')\n\nSchema can be defined manually, or can be created via standard frictionless functions.\n\nimport frictionless\n\nfrictionless.Schema.describe(os.path.join(RESOURCE_DIR, TABLE_FILE_NAME)).to_yaml(os.path.join(RESOURCE_DIR, TABLE_SCHEMA_NAME)) ## Create a default schema and save as a yaml\n\n","type":"content","url":"/morpc-py-demos#morpc-frictionless-schema-tools-tableschema","position":35},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl4":"Create a resource","lvl2":"morpc.frictionless - Schema tools (TableSchema)"},"type":"lvl4","url":"/morpc-py-demos#create-a-resource","position":36},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl4":"Create a resource","lvl2":"morpc.frictionless - Schema tools (TableSchema)"},"content":"\n\nmorpc.frictionless.create_resource(TABLE_FILE_NAME, # the filename relative to resource dir, often just filename\n                                   resourcePath=os.path.join(RESOURCE_DIR, TABLE_RESOURCE_NAME), # file path to resource location\n                                   schemaPath=TABLE_SCHEMA_NAME, # path of schema relative to resource dir\n                                   name = \"temp_df\", # simple name\n                                   title = \"A title for the resource\", # A human readable title\n                                   description = \"A description of the resource to explain what it contains.\", # A full description\n                                   writeResource = True, # Boolean - Whether to archive the resouce file \n                                   resFormat = \"csv\",\n                                   resMediaType= \"text/csv\",  \n                                   computeBytes= True, # Compute the size if the file in bytes\n                                   computeHash = True, # Create a md5 hash of the file, a unique string to check if file has been changed.\n                                   validate=True # Validate the resource after creating\n                                  )\n\nLoad data from a resource file. Returns the data, a resource, and the schema\n\n","type":"content","url":"/morpc-py-demos#create-a-resource","position":37},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl4":"Load data from a resource file","lvl2":"morpc.frictionless - Schema tools (TableSchema)"},"type":"lvl4","url":"/morpc-py-demos#load-data-from-a-resource-file","position":38},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl4":"Load data from a resource file","lvl2":"morpc.frictionless - Schema tools (TableSchema)"},"content":"\n\ndata, resource, schema = morpc.frictionless.load_data(os.path.join(RESOURCE_DIR, TABLE_RESOURCE_NAME))\n\ndata\n\nresource\n\nschema\n\n","type":"content","url":"/morpc-py-demos#load-data-from-a-resource-file","position":39},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl2":"Branding"},"type":"lvl2","url":"/morpc-py-demos#branding","position":40},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl2":"Branding"},"content":"\n\nimport morpc\nimport yaml\nimport pandas as pd\nimport numpy as np\n\nThe library includes the hex codes the MORPC brand colors and provides assigns of human-readable names to make the colors easier to work with.\n\nwith open('../morpc/color/morpc_colors.yaml', 'r') as file:\n    morpc_colors = yaml.safe_load(file)\n\ndef arc_points(start_angle_deg, end_angle_deg, radius=1.0, center=(0, 0), n_points=100):\n    \"\"\"\n    Generate points along an arc.\n\n    Parameters:\n    - start_angle_deg (float): Start angle in degrees\n    - end_angle_deg (float): End angle in degrees\n    - radius (float): Radius of the arc\n    - center (tuple): (x, y) center of the arc\n    - n_points (int): Number of points along the arc\n\n    Returns:\n    - List of (x, y) points\n    \"\"\"\n    angles = np.radians(np.linspace(start_angle_deg, end_angle_deg, n_points))\n    cx, cy = center\n    x = cx + radius * np.cos(angles)\n    y = cy + radius * np.sin(angles)\n    return x, y\n\nimport matplotlib.pyplot as plt\nimport colorsys\nimport pandas as pd\n\ndef plot_hls_dataframe(df):\n    \"\"\"\n    Plot HLS colors from a DataFrame with 'hue', 'lum', and 'sat' columns.\n\n    Parameters:\n    - df (pd.DataFrame): DataFrame with columns ['hue', 'lum', 'sat'], all in range [0, 1]\n    \"\"\"\n    if not all(col in df.columns for col in ['hue', 'lum', 'sat']):\n        raise ValueError(\"DataFrame must contain 'hue', 'lum', and 'sat' columns\")\n\n    n = len(df)\n    fig, ax = plt.subplots(figsize=(n, 1.5))\n    ax.axis('off')\n\n    for i, row in df.iterrows():\n        h, l, s = row['hue'], row['lum'], row['sat']\n        rgb = colorsys.hls_to_rgb(h, l, s)\n        rect = plt.Rectangle((i, 0), 1, 1, color=rgb)\n        ax.add_patch(rect)\n\n    ax.set_xlim(0, n)\n    ax.set_ylim(0, 1)\n    plt.tight_layout()\n    plt.show()\n\ndef arc_points(start_angle_deg, end_angle_deg, radius=1.0, center=(0, 0), n_points=100):\n    angles = np.radians(np.linspace(start_angle_deg, end_angle_deg, n_points))\n    cx, cy = center\n    x = cx + radius * np.cos(angles)\n    y = cy + radius * np.sin(angles)\n    return x, y\n\nimport numpy as np\nimport pandas as pd\nfrom plotnine import ggplot, aes, geom_line, labs, theme_minimal\n\ndef plot_parabolas_plotnine(a_values, x_range=(-1, 1), num_points=300):\n    \"\"\"\n    Plot parabolas y = a * x^2 for different 'a' values using plotnine.\n\n    Parameters:\n    - a_values (list): List of 'a' coefficients\n    - x_range (tuple): x-axis range\n    - num_points (int): Number of points for each parabola\n    \"\"\"\n    x = np.linspace(*x_range, num_points)\n    data = []\n\n    for a in a_values:\n        y = a * x**2\n        for xi, yi in zip(x, y):\n            data.append({'x': xi, 'y': yi, 'a': f'a = {a}'})\n\n    df = pd.DataFrame(data)\n\n    plot = (\n        ggplot(df, aes(x='x', y='y', color='a')) +\n        geom_line(size=1) +\n        labs(title=\"Parabolas with Varying Coefficients (a)\",\n             x='x', y='y') +\n        theme_minimal()\n    )\n\n    return plot\n\ndef parabola(xs, a, h, k):\n    ys = []\n    for x in xs:\n        y = a * (x - h)**2 + k \n        ys.append(y)\n    return ys\n\nparabola(np.linspace(0,1,12), 1, 1, 2)\n\nscale = morpc.color.rgb_scale_from_hue(**morpc_colors['darkblue']['gradient'])\nposition = morpc_colors['darkblue']['gradient_pos']\n\nmorpc_colors['darkgreen']['hex']\n\nmorpc.color.hex_to_hls('#66b561')\n\npd.DataFrame({\"x\": greys,\n              \"y\": sats}).set_index('y').plot()\n\nhue = .3234\ngreys = [.92, .84, .76, .68, .60, .52, .46, .38, .30, .22, .16, .08]\nsats  = [.14, .19, .28, .32, .38, .40, .52, .67, .67, .51, .48, .44]\n\nscale = morpc.color.rgb_scale_from_hue(hue, sats, greys)\n\nmorpc.color.plot_rgb_squares_with_hex(scale, 5)\n\n","type":"content","url":"/morpc-py-demos#branding","position":41},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl2":"Round preserving sum (aka “bucket rounding”)"},"type":"lvl2","url":"/morpc-py-demos#round-preserving-sum-aka-bucket-rounding","position":42},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl2":"Round preserving sum (aka “bucket rounding”)"},"content":"\n\nImagine we have a series of values that need to be rounded, but we want the rounded values to sum to the same value as the original series.  Create a random series for demonstration purposes.\n\nrawValues = pd.Series([random.randrange(0, 100000)/100 for x in range(1,10)])\nlist(rawValues)\n\nSpecify the number of decimal digits to preserve. For this demo we’ll round to integers (i.e. zero decimal places), which is typically what we want, but the function supports rounding to other decimal places as well.\n\ndigits = 0\n\nPerform bucket-rounding\n\nbucketRoundedValues = morpc.round_preserve_sum(rawValues, digits, verbose=True)\n\nRaw values:\n\nrawValues.tolist()\n\nBucket-rounded values:\n\nbucketRoundedValues.tolist()\n\nSum of raw values:\n\nround(sum(rawValues))\n\nSum of bucket-rounded values:\n\nsum(bucketRoundedValues)\n\n","type":"content","url":"/morpc-py-demos#round-preserving-sum-aka-bucket-rounding","position":43},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl2":"Control variable to group"},"type":"lvl2","url":"/morpc-py-demos#control-variable-to-group","position":44},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl2":"Control variable to group"},"content":"\n\nOften we have a set of values representing the members of some group and we need the sum of those values to match a total for the group that was computed independently. Perhaps the best known example of this is the annual \n\npopulation estimates for sub-county jurisdictions.  The estimates for all of the jurisdictions in the county must total to the \n\ncounty-level population estimates, which are derived independently.  In this case the county (group) totals are known as the “control values” or “control totals” and the process of adjusting the sub-county (group member) values so that their total is equal to the control total is known as “controlling” the variable.  The process includes the following steps, which will be described in more detail below.\n\nEstablish control values for the groups (e.g. the county-level estimnates in the example above)\n\nCreate a series of grouped values to be controlled (e.g. the sub-county estimates)\n\nControl the values in each group to the control total.  This consists of three sub-parts:\n\nCompute group sums\n\nCompute group shares\n\nCompute controlled values\n\nIn the sections that follow, we’ll look at a more contrived example, namely controlling the 2021 ACS 5-year estimates for county subdivisions to the 2020 decennial county populations. This is not a recommended application and is used only for the sake of convenience.\n\n","type":"content","url":"/morpc-py-demos#control-variable-to-group","position":45},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl4":"Establish control values for groups","lvl2":"Control variable to group"},"type":"lvl4","url":"/morpc-py-demos#establish-control-values-for-groups","position":46},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl4":"Establish control values for groups","lvl2":"Control variable to group"},"content":"\n\nDownload county populations from 2020 decennial census\n\nr = requests.get(\n    url=\"https://api.census.gov/data/2020/dec/dhc\",\n    params={\n        \"get\":\",\".join([\"P1_001N\"]),\n        \"for\":\"county:{}\".format(\",\".join([x[2:] for x in countyLookup.list_ids()])),\n        \"in\": \"state:39\"\n        }\n)\nrecords = r.json()\ncountyPop = pd.DataFrame.from_records(records[1:], columns=records[0])\ncountyPop[\"C_GEOID\"] = countyPop[\"state\"] + countyPop[\"county\"]\ncountyPop = countyPop.loc[countyPop[\"county\"].isin([x[2:] for x in countyLookup.list_ids()])].copy() \\\n    .rename(columns={\"P1_001N\":\"C_POP\"}) \\\n    .drop(columns={\"state\",\"county\"}) \\\n    .astype({\"C_POP\":\"int\"}) \\\n    .set_index(\"C_GEOID\")\n\nNow we have the population for each county (indexed by their GEOIDs) which will serve as the control totals.\n\ncountyPop.head()\n\n","type":"content","url":"/morpc-py-demos#establish-control-values-for-groups","position":47},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl4":"Create series of grouped values to be controlled","lvl2":"Control variable to group"},"type":"lvl4","url":"/morpc-py-demos#create-series-of-grouped-values-to-be-controlled","position":48},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl4":"Create series of grouped values to be controlled","lvl2":"Control variable to group"},"content":"\n\nDownload sub-county populations from the 2021 ACS 5-year estimates\n\nr = requests.get(\n    url=\"https://api.census.gov/data/2021/acs/acs5\",\n    params={\n        \"get\":\",\".join([\"NAME\",\"GEO_ID\",\"B01001_001E\",\"B01001_001M\"]),\n        \"for\":\"county subdivision:*\",\n        \"in\": [\n            \"state:39\",\n            \"county:{}\".format(\",\".join([x[2:] for x in countyLookup.list_ids()])),\n        ]\n    }\n)\nrecords = r.json()\nsubdivPop = pd.DataFrame.from_records(records[1:], columns=records[0])\nsubdivPop = subdivPop \\\n    .rename(columns={\"GEO_ID\":\"GEOID\",\"B01001_001E\":\"POP\",\"B01001_001M\":\"POP_MOE\"}) \\\n    .astype({\"POP\":\"int\"}) \\\n    .set_index(\"GEOID\")\nsubdivPop[\"C_GEOID\"] = subdivPop[\"state\"] + subdivPop[\"county\"]\n\nNow we have population estimates for the members of each group (county).  Note that the county GEOID (C_GEOID) has been assigned to each member record.  We’ll use this to iterate through groups.\n\nsubdivPop.head()\n\nNote that the sums of the subdivision populations doesn’t match the sum of the county populations. This is expected and it is the reason we need to control the subdivision values.\n\nsubdivPop[\"POP\"].sum()\n\ncountyPop[\"C_POP\"].sum()\n\n","type":"content","url":"/morpc-py-demos#create-series-of-grouped-values-to-be-controlled","position":49},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl4":"Control the values in each group to the control total","lvl2":"Control variable to group"},"type":"lvl4","url":"/morpc-py-demos#control-the-values-in-each-group-to-the-control-total","position":50},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl4":"Control the values in each group to the control total","lvl2":"Control variable to group"},"content":"\n\nRecall that this step has three sub-parts:\n\nCompute group sums (see morpc.compute_group_sum())\n\nCompute group shares (see morpc.compute_group_share())\n\nCompute controlled values (see morpc.compute_controlled_values())\n\nThe morpc-common library has a function for each of these steps as noted above, but it also has a high-level function that performs all three steps in sequence, namely morpc.control_variable_to_group().  It requires the following inputs:\n\ninputDf is a pandas DataFrame with a column containing the group shares and (optionally) a column containg the group labels.\n\ncontrolValues is one of the following:\n\nIf groupbyField == None: controlValues is a scalar number (integer or float)\n\nIf groupbyField != None: controlValues is a pandas Series of numbers indexed by group labels\n\ngroupbyField (optional) is the name of the column of inputDf that contains the group labels.\n\nshareField (optional) is the name of the column of inputDf containing the shares that the values comprise.  If this is not specified, “GROUP_SHARE” will be used.\n\nroundPreserveSumDigits (optional) is the number of decimal places that the scaled values (i.e. the values in the “CONTROLLED_VALUE” column) should be rounded to. A “bucket rounding” technique (see morpc.round_preserve_sum() will be used to ensure that the sum of the values in the group is preserved. If this is not specified, the scaled values will be left unrounded.\n\nThis is what the function call looks like for our example case:\n\nsubdivPopControlled = morpc.control_variable_to_group(inputDf=subdivPop, controlValues=countyPop[\"C_POP\"], valueField=\"POP\", groupbyField=\"C_GEOID\", roundPreserveSumDigits=0)\nsubdivPopControlled.head()\n\n","type":"content","url":"/morpc-py-demos#control-the-values-in-each-group-to-the-control-total","position":51},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl4":"Check the results","lvl2":"Control variable to group"},"type":"lvl4","url":"/morpc-py-demos#check-the-results","position":52},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl4":"Check the results","lvl2":"Control variable to group"},"content":"\n\nNow the sum of our controlled values should match the county control totals.  We can see that this is true by comparing the “POP_SUM_CONTROLLED” columns (which the sum of “CONTROLLED_VALUE” by county) and the “C_POP” column (which is the county control total) and verifying that the two are equal for all records.\n\nsubdivPopControlled[[\"C_GEOID\",\"POP\",\"CONTROLLED_VALUE\"]] \\\n    .groupby(\"C_GEOID\").sum() \\\n    .rename(columns={\"POP\":\"POP_SUM\",\"CONTROLLED_VALUE\":\"POP_SUM_CONTROLLED\"}) \\\n    .join(countyPop)\n\nWe may want to get a sense of how much adjustment of the sub-county values was required. To do this we can compute the difference between the controlled value and the original value and do some desriptive analysis.\n\nsubdivPopControlled[\"RESIDUAL\"] = subdivPopControlled[\"CONTROLLED_VALUE\"] - subdivPopControlled[\"POP\"]\nsubdivPopControlled[\"RESIDUAL_PCT\"] = subdivPopControlled[\"RESIDUAL\"]/subdivPopControlled[\"POP\"]\nsubdivPopControlled[\"RESIDUAL_PCT\"] = subdivPopControlled[\"RESIDUAL_PCT\"].replace(np.inf, 0)\nsubdivPopControlled[\"RESIDUAL_PCT\"] = subdivPopControlled[\"RESIDUAL_PCT\"].replace(-np.inf, 0)\nsubdivPopControlled[\"RESIDUAL_PCT\"] = subdivPopControlled[\"RESIDUAL_PCT\"].fillna(0)\n\nFirst we’ll look at the stats for the raw residual.\n\nsubdivPopControlled[\"RESIDUAL\"].describe()\n\nsubdivPopControlled[\"RESIDUAL\"].hist(bins=25, log=True)\n\nThe residual is close to zero in the vast majority of cases.  Let’s look at the ten cases with the greatest residual.\n\nsubdivPopControlled[[\"NAME\",\"POP\",\"CONTROLLED_VALUE\",\"RESIDUAL\",\"RESIDUAL_PCT\"]].sort_values(\"RESIDUAL\", ascending=False).head(10)\n\nAnd the ten cases with the smallest residual (which could be large but negative)\n\nsubdivPopControlled[[\"NAME\",\"POP\",\"CONTROLLED_VALUE\",\"RESIDUAL\",\"RESIDUAL_PCT\"]].sort_values(\"RESIDUAL\", ascending=False).tail(10)\n\nThe raw residual for Columbus was very large, but as a percentage it is not that bad.  Let’s look at the stats for the percentages.\n\nsubdivPopControlled[\"RESIDUAL_PCT\"].describe()\n\nsubdivPopControlled[\"RESIDUAL_PCT\"].hist(bins=25)\n\nsubdivPopControlled[[\"NAME\",\"POP\",\"CONTROLLED_VALUE\",\"RESIDUAL\",\"RESIDUAL_PCT\"]].sort_values(\"RESIDUAL_PCT\", ascending=False).head(10)\n\nsubdivPopControlled[[\"NAME\",\"POP\",\"CONTROLLED_VALUE\",\"RESIDUAL\",\"RESIDUAL_PCT\"]].sort_values(\"RESIDUAL_PCT\", ascending=False).tail(10)\n\n","type":"content","url":"/morpc-py-demos#check-the-results","position":53},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl2":"morpc.census"},"type":"lvl2","url":"/morpc-py-demos#morpc-census","position":54},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl2":"morpc.census"},"content":"\n\nMORPC works regularly with census data, including but not limited to ACS 5 and 1-year, Decennial Census, PEP, and geographies. The following module is useful for gathering and organizing census data for processes in various workflow. Those workflows are linked when appropriate.\n\n","type":"content","url":"/morpc-py-demos#morpc-census","position":55},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl4":"ACS functions and variables","lvl2":"morpc.census"},"type":"lvl4","url":"/morpc-py-demos#acs-functions-and-variables","position":56},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl4":"ACS functions and variables","lvl2":"morpc.census"},"content":"\n\nacs_get() is a low-level wrapper for Census API requests that returns the results as a pandas dataframe. If necessary, it splits the request into several smaller requests to bypass the 50-variable limit imposed by the API.\n\nThe resulting dataframe is indexed by GEOID (regardless of whether it was requested) and omits other fields that are not requested but which are returned automatically with each API request (e.g. “state”, “county”)\n\nurl = 'https://api.census.gov/data/2022/acs/acs1'\nparams = {\n    \"get\": \"GEO_ID,NAME,B01001_001E\",\n    \"for\": \"county:049,041\",\n    \"in\": \"state:39\"\n}\n\nacs = morpc.census.acs_get(url, params)\n\nacs\n\n","type":"content","url":"/morpc-py-demos#acs-functions-and-variables","position":57},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl4":"Using morpc-censusacs-fetch as an input","lvl2":"morpc.census"},"type":"lvl4","url":"/morpc-py-demos#using-morpc-censusacs-fetch-as-an-input","position":58},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl4":"Using morpc-censusacs-fetch as an input","lvl2":"morpc.census"},"content":"\n\nWhen using ACS data, generally we will be digesting data produded using the \n\nmorpc​-censusacs​-fetch workflow. The data that is produced from that script is by default saved in its output_data folders ./morpc-censusacs-fetch/output_data/\n\nRun that script according to the documentation and then use acs_generate_dimension_table() downstream.\n\n","type":"content","url":"/morpc-py-demos#using-morpc-censusacs-fetch-as-an-input","position":59},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl5":"Load the data using frictionless.load_data()","lvl4":"Using morpc-censusacs-fetch as an input","lvl2":"morpc.census"},"type":"lvl5","url":"/morpc-py-demos#load-the-data-using-frictionless-load-data","position":60},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl5":"Load the data using frictionless.load_data()","lvl4":"Using morpc-censusacs-fetch as an input","lvl2":"morpc.census"},"content":"\n\ndata, resource, schema = morpc.frictionless.load_data('../../morpc-censusacs-fetch/output_data/morpc-acs5-2023-us-B01001.resource.yaml', verbose=False)\n\ndata\n\n","type":"content","url":"/morpc-py-demos#load-the-data-using-frictionless-load-data","position":61},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl5":"Using ACS_ID_FIELDS to get the fields ids","lvl4":"Using morpc-censusacs-fetch as an input","lvl2":"morpc.census"},"type":"lvl5","url":"/morpc-py-demos#using-acs-id-fields-to-get-the-fields-ids","position":62},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl5":"Using ACS_ID_FIELDS to get the fields ids","lvl4":"Using morpc-censusacs-fetch as an input","lvl2":"morpc.census"},"content":"\n\nidFields = [field[\"name\"] for field in morpc.census.ACS_ID_FIELDS['us']]\n\nmorpc.acs_generate_universe_table(data.set_index(\"GEO_ID\"), \"B01001_001\")\n\n","type":"content","url":"/morpc-py-demos#using-acs-id-fields-to-get-the-fields-ids","position":63},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl5":"Create a dimension table with the data and the dimension names","lvl4":"Using morpc-censusacs-fetch as an input","lvl2":"morpc.census"},"type":"lvl5","url":"/morpc-py-demos#create-a-dimension-table-with-the-data-and-the-dimension-names","position":64},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl5":"Create a dimension table with the data and the dimension names","lvl4":"Using morpc-censusacs-fetch as an input","lvl2":"morpc.census"},"content":"\n\ndim_table = morpc.census.acs_generate_dimension_table(data.set_index(\"GEO_ID\"), schema, idFields=idFields, dimensionNames=[\"Sex\", \"Age group\"])\n\ndim_table.loc[dim_table['Variable type'] == 'Estimate'].head()\n\n","type":"content","url":"/morpc-py-demos#create-a-dimension-table-with-the-data-and-the-dimension-names","position":65},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl2":"Plotting"},"type":"lvl2","url":"/morpc-py-demos#plotting","position":66},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl2":"Plotting"},"content":"\n\nimport morpc\nimport pandas as pd\nimport numpy as np\nimport random\nimport colorsys\nimport matplotlib.pyplot as plt\n\n\ndf = pd.DataFrame({\"x\": [x for x in np.random.binomial(2000, .1, 100)],\n              \"y\": [x for x in np.random.exponential(2,100)],\n              \"color\": [random.choice(['a','b','c','d']) for n in range(100)]\n              })\n\nplot = morpc.plot.scatter_plot(df, x = 'x', y = \"y\", color='color')\n\nplot.jupyter_plot()\n\n","type":"content","url":"/morpc-py-demos#plotting","position":67},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl2":"Schema tools (Apache Avro format) - DEPRECIATED"},"type":"lvl2","url":"/morpc-py-demos#schema-tools-apache-avro-format-depreciated","position":68},{"hierarchy":{"lvl1":"Demos of features of the morpc python package","lvl2":"Schema tools (Apache Avro format) - DEPRECIATED"},"content":"\n\nDEPRECATION WARNING:  As of January 2024 the Data Team is considering a new standard for machine-readable metadata, namely TableSchema (see below).  Code that makes use of the features described in this section will likely need to be updated to make use of the new standard when it is adopted. Use discretion when making use of these features.\n\nApache Avro is an open source data serialization technology that includes a JSON-based \n\nschema specification format.  MORPC does not typically use the Avro format itself, however code written through 2023 may have relied on schemas specified in Avro format.  This section demonstrates utility functions for loading Avro-formatted schemas and using the schemas to manipulate data.\n\nThe demonstration relies on a local copy of data from the \n\nmorpc-lookup repository in GitHub.  Prior to running the code you must download the required data and schema and update the following paths (as needed) to point to the correct files.\n\ndataPath = \"..\\morpc-lookup\\MORPC_Counties.csv\"\nschemaPath = dataPath.replace(\".csv\", \"_schema.json\")\nprint(\"Data path: {}\".format(dataPath))\nprint(\"Schema path: {}\".format(schemaPath))\n\nLoad the data.\n\ndataRaw = pd.read_csv(dataPath)\ndataRaw.head()\n\nThe data is stored in a CSV file.  In a CSV, all data is stored as strings.  There is no built-in mechanism for specifying the data type for each field. Note that pandas (like many other software applications) tried to infer the data type.\n\ndataRaw.dtypes\n\nSometimes the inference works well, other times not so well.  It is safer to specify the field types explictly.  One way to do this is to create a schema definition for the data.  Here is an example of a schema definition specified in Apache Avro format:\n\nwith open(schemaPath, \"r\") as f:\n    schemaRaw = f.read()\nprint(schemaRaw)\n\nNote that that this format allows for specification of the field names and types, as well as dataset-level and variable-level metadata. Because Avro-style schemas are formatted as JSON, Python can easily convert the schema to a dictionary structure so that we can access it programmatically. The morpc-common library contains a convenience function to load the schema and convert it to a dictionary.\n\nschema = morpc.load_avro_schema(schemaPath)\nprint(\"The fields in this dataset are: \" + \", \".join([field[\"name\"] for field in schema[\"fields\"]]))\n\nThe morpc-common library contains several convenience functions for interacting with Avro schemas.  One such function casts each of the fields in a dataset as the correct data type as specified in the schema.\n\ndata = morpc.cast_field_types(dataRaw, schema)\n\nNow the data types should match the schema, regardless of what pandas inferred originally.\n\ndata.dtypes\n\nA note about integers  The pandas “int” dtype does not support null values.  If a field contains null values and you try to cast it as “int”, this function will automatically attempt to convert them to “Int64” (which does support null values) instead.  If this fails, it might be because the fractional part of one of your values (i.e. the part to the right of the decimal point) is non-zero.  You can either round the values before attempting the conversion or set forceInteger=True when calling the function. In the latter case, the function will round the values to the ones place prior to recasting the values.\n\nHere’s another function that creates a list object containing the names of the fields included in the schema.\n\nmorpc.avro_get_field_names(schema)\n\nThis one returns a dictionary mapping each field name to its type.\n\nmorpc.avro_to_pandas_dtype_map(schema)\n\nSometimes a variable may be referred to by different names. It is possible to list the alternate names in the schema using the “aliases” property. The following function creates a dictionary that maps the original field name to the first (and presumably most common) alias.  This can be used to easily rename the fields in the dataset for use in a different application.\n\nmorpc.avro_map_to_first_alias(schema)\n\nThe following function does the reverse of the previous one, namely it creates a dictionary mapping the first alias to the original field name.  This can be useful to reverse the previous remapping.  It is also useful for Shapefiles, which have a ten-character field name limit.  In that case, you can store the human-readable field name as the original field name and store the Shapefile-compliant field name as an alias.\n\nmorpc.avro_map_from_first_alias(schema)\n\nUsing the schema dictionary and the helper functions, you can easily do transformations of the data.  Here are some examples. First, take a look at the original data.\n\ndata.head()\n\nRename the columns in the data to the first alias for each column.\n\ndata.rename(columns=morpc.avro_map_to_first_alias(schema)).head()\n\nFilter and reorder fields.\n\nreverseOrder = morpc.avro_get_field_names(schema)\nreverseOrder.reverse()\ndata[reverseOrder].head()\n\noneLessField = morpc.avro_get_field_names(schema)\noneLessField.remove(\"STATE_ID\")\ndata[oneLessField].head()","type":"content","url":"/morpc-py-demos#schema-tools-apache-avro-format-depreciated","position":69},{"hierarchy":{"lvl1":"MORPC ArcGIS REST API Tools"},"type":"lvl1","url":"/morpc-restapi-demo","position":0},{"hierarchy":{"lvl1":"MORPC ArcGIS REST API Tools"},"content":"","type":"content","url":"/morpc-restapi-demo","position":1},{"hierarchy":{"lvl1":"MORPC ArcGIS REST API Tools","lvl2":"Introduction"},"type":"lvl2","url":"/morpc-restapi-demo#introduction","position":2},{"hierarchy":{"lvl1":"MORPC ArcGIS REST API Tools","lvl2":"Introduction"},"content":"\n\nMany spatial data sets are stored in ArcGIS online and are available through the REST API. This set of scripts uses the frictionless framework to document and download data. It reads available metadata and iteratively downloads the data in GeoJSON format and returns a GDF, and optionally archives the file.\n\nimport morpc\n\n","type":"content","url":"/morpc-restapi-demo#introduction","position":3},{"hierarchy":{"lvl1":"MORPC ArcGIS REST API Tools","lvl2":"Creating a resource file"},"type":"lvl2","url":"/morpc-restapi-demo#creating-a-resource-file","position":4},{"hierarchy":{"lvl1":"MORPC ArcGIS REST API Tools","lvl2":"Creating a resource file"},"content":"\n\ntest_url = 'https://tigerweb.geo.census.gov/arcgis/rest/services/TIGERweb/CBSA/MapServer/3'\n\nresource = morpc.rest_api.resource_from_services_url(test_url)\nresource\n\nresource.to_json('../docs/temp_data/rest_resource.json')\n\nkey = morpc.rest_api.get_api_key('./temp_data/api_key.txt')\n\nf\"{resource.path}/query?outFields=*&where=1%3D1&f=geojson&key={key}\"\n\nmorpc.rest_api.gdf_from_rest_resource('../docs/temp_data/rest_resource.json', api_key=key)","type":"content","url":"/morpc-restapi-demo#creating-a-resource-file","position":5}]}